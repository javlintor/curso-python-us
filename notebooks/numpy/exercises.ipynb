{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyrj7XXaLx9I"
      },
      "source": [
        "# Ejercicios "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwQN5-E3Lx9K"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98kDIjjPfqtK"
      },
      "source": [
        "---\n",
        "## Convoluciones de arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCffwlpsf0rF"
      },
      "source": [
        ":::{exercise}\n",
        ":label: chapther2-convolution\n",
        "\n",
        "Dadas dos funciones de variable real $f$ y $g$, definimos la [**convolución**](https://en.wikipedia.org/wiki/Convolution) de $f$ y $g$ como\n",
        "\n",
        "$$\n",
        "(f*g)(x) = \\int_\\mathbb{R} f(t)g(x - t)dt.\n",
        "$$\n",
        "\n",
        "La versión discreta de la anterior definición puede ser la siguiente. Datos $f=(f_0, \\dots, f_{n-1})$ y $g=(g_0, \\dots, g_{m-1})$ dos vectores (representados por arrays unidimensionales) de tamaño $n$ y $m$, respectivamente, definimos el array `conv` de dimensión `n + m - 1` cuya componente $k$ vale \n",
        "\n",
        "$$\n",
        "\\sum_{i + m -1 = k + j}f_ig_j\n",
        "$$\n",
        "\n",
        "para $0 \\leq k \\leq n + m - 1$. \n",
        "\n",
        "Crea una función `conv` que tome como inputs dos arrays y devuelva la convolución de ambos. Por ejemplo \n",
        "\n",
        "```\n",
        "arr1 = np.arange(10)\n",
        "arr2 = np.arange(5) \n",
        "conv(arr1, arr2)\n",
        ">>> [ 0  4 11 20 30 40 50 60 70 80 50 26  9  0]\n",
        "```\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-7rOlfiLx9N"
      },
      "source": [
        ":::{solution} chapther2-convolution\n",
        ":class: dropdown\n",
        "\n",
        "Una primera solución iterando sobre todos las posibles combinaciones de $i$ y $j$ para cada $k$\n",
        "```\n",
        "from itertools import product\n",
        "\n",
        "def conv(f, g):\n",
        "    n = f.shape[0]\n",
        "    m = g.shape[0]\n",
        "    conv_dim = n + m - 1\n",
        "    arr_conv = np.zeros(conv_dim, dtype=f.dtype)\n",
        "    for k in range(conv_dim):\n",
        "        my_gen = (\n",
        "            f[i]*g[j] for i, j in product(range(n), range(m)) \\\n",
        "                if i + m - 1 == j + k\n",
        "        )\n",
        "        arr_conv[k] = sum(my_gen)\n",
        "    return arr_conv\n",
        "```\n",
        "\n",
        "Otra solución más directa considerando la matrix *producto exterior* de $f$ y $g$ y sumando las diagonales \n",
        "\n",
        "```\n",
        "def conv2(f, g):\n",
        "    i = f.shape[0]\n",
        "    j = g.shape[0]\n",
        "    outer_mat = np.outer(f, g).T\n",
        "    c = np.array([np.trace(outer_mat, offset=k) for k in range(-j + 1, i)])\n",
        "    return c\n",
        "```\n",
        "\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GenuRidKC9X7"
      },
      "source": [
        "---\n",
        "## Procesando imágenes con numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAFncJvvL9N0"
      },
      "source": [
        ":::{exercise}\n",
        ":label: chapther2-images\n",
        "\n",
        "Una de las posibles técnicas que existen para comprimir una imagen es utilizar [la descomposición SVD (Singular Value Decomposition)](https://en.wikipedia.org/wiki/Singular_value_decomposition) que nos permite expresar una matrix $A$ de dimensiones $n\\times m$ como un producto\n",
        "\n",
        "$$ \n",
        "A = U \\Sigma V^t\n",
        "$$\n",
        "\n",
        "donde $U$ y $V$ son cuadradas de dimensiones $n$ y $m$ respectivamente y $\\Sigma$ es diagonal y está formada por los [valores singulares](https://en.wikipedia.org/wiki/Singular_value) de $A$ ordenados de mayor a menor. \n",
        "\n",
        "Recuerda que una imagen no es más que un conjunto de 3 matrices, cada una representando la intensidad de la grilla de píxeles para cada color (rojo, verde y azul). Una forma de comprimir una imagen consiste en quedarse con los $k$ primeros valores singulares para cada color e intercambiar $k$ por una se las dimensiones que representan el alto o el ancho de la imagen. \n",
        "\n",
        "Crea una función `aproxima_img` que tome un array de dimensión $(3, h, w)$ y devuelva otra imagen aproximada de dimensión $(3, h, w)$ utilizando los k primeros valores singulares. Para ello, \n",
        "1. Utiliza la función `misc.face` para generar una imagen de prueba, o también puedes importar una utilizando `im = cv2.imread(\"img.jpg\")`. Puedes visualizar imágenes con este formato a través del la función `imshow` de `matplotlib.pyplot` (a veces hay que cambiar de orden los canales).\n",
        "2. Utiliza la función `svd` de `np.linalg` para realizar la descomposición SVD. Mucho cuidado con las dimensiones que espera la función. \n",
        "3. Otras funciones que pueden ser útiles para el ejercicio: `np.transpose`, `np.zeros`, `np.fill_diagonal`, `np.clip`.\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AEvYyJYGJ7W"
      },
      "source": [
        ":::{exercise}\n",
        ":label: chapter2-images-convolution\n",
        "\n",
        "Importa una imagen de tu elección utilizando la función `imread` de la librería `cv2`. Crea un array `kernel` de dimensión $(n, n)$ y realiza la convolución de tu imagen con `kernel` mediante la función [`scipy.signal.convolve2d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html#scipy.signal.convolve2d) (parámetro `mode='same'`). Si tu imagen tiene varios canales para los colores, aplica el mismo kernel a cada canal.\n",
        "\n",
        "Algunos ejemplos interesantes de kernel pueden ser los siguientes:\n",
        "\n",
        "- $n = 3$ con valores \n",
        "\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "-3 & 0 & 3\\\\\n",
        "-10 & 0 & 10\\\\\n",
        "-3 & 0 & 3\n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n",
        "- transpuesta del anterior, \n",
        "\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "-3 & -10 & -3\\\\\n",
        "0 & 0 & 0\\\\\n",
        "3 & 10 & 3\n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n",
        "- $n \\approx 50$, generados con `scipy.signal.windows.gaussian` (puedes utilizar la función `np.outer` para realizar un producto exterior)\n",
        "\n",
        "- Operador complejo de Sharr\n",
        "```\n",
        "scharr = np.array([[ -3-3j, 0-10j,  +3 -3j],\n",
        "\n",
        "                   [-10+0j, 0+ 0j, +10 +0j],\n",
        "\n",
        "                   [ -3+3j, 0+10j,  +3 +3j]])\n",
        "```\n",
        "Puedes visualizar las imágenes con `matplotlib.pyplot.imshow`.\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ":::{exercise}\n",
        ":label: chapter2-linear-regression\n",
        "\n",
        "Considera un modelo de regresión lineal que consiste en estimar una variable $y$ como una suma ponderada de un cojunto de variables regresoras \n",
        "\n",
        "$$\n",
        "\\hat{y} = \\theta_0 + \\theta_1x_1 + \\dots \\theta_nx_n\n",
        "$$\n",
        "\n",
        "donde \n",
        "\n",
        "- $n$ es el conjunto de variables regresoras o *features*, $x_i$ el valor correspondiente.\n",
        "- $\\hat{y}$ es el valor predicho. \n",
        "- $\\theta_i$ son parámetros del modelo para $0 \\leq i \\leq n$.  \n",
        "\n",
        "Podemos expresar dicha ecuación en formato matricial como\n",
        "\n",
        "$$\n",
        "\\hat{y} = \n",
        "\\begin{pmatrix}\n",
        "1 & x_1 & \\cdots & x_n\n",
        "\\end{pmatrix} \n",
        "\\begin{pmatrix}\n",
        "\\theta_0 \\\\\n",
        "\\theta_1 \\\\\n",
        "\\vdots \\\\\n",
        "\\theta_n\n",
        "\\end{pmatrix} \n",
        "=\n",
        "\\boldsymbol{x} \\cdot \\boldsymbol{\\theta}.\n",
        "$$\n",
        "\n",
        "Dado un conjunto de $m$ observaciones, nuestro objetivo es encontrar $\\boldsymbol{\\theta}$ tal que se minimice nuestra aproximación lineal en términos de menores cuadrados \n",
        "\n",
        "$$\n",
        "\\frac{1}{m}\\sum_{i=1}^{m} \n",
        "(\\boldsymbol{x}_i \\cdot \\boldsymbol{\\theta} - y_i)^2.\n",
        "$$\n",
        "\n",
        "El valor óptimo de los parámetros se puede calcular directamente \n",
        "\n",
        "$$\n",
        "\\hat{\\theta} = (\\boldsymbol{X}^t\\boldsymbol{X})^{-1}\\boldsymbol{X}^ty\n",
        "$$\n",
        "\n",
        "donde \n",
        "\n",
        "$$\n",
        "\\boldsymbol{X} = \n",
        "\\begin{pmatrix}\n",
        "1 & x_{11} & \\cdots & x_{1n} \\\\\n",
        "1 & x_{21} & \\cdots & x_{2n} \\\\\n",
        "\\vdots & \\vdots & \\cdots & \\vdots \\\\\n",
        "1 & x_{m1} & \\cdots & x_{mn} \n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "es el conjunto de observaciones de las variables regresoras e\n",
        "\n",
        "$$\n",
        "\\hat{y}=\n",
        "\\begin{pmatrix}\n",
        "y_0 \\\\\n",
        "y_1 \\\\\n",
        "\\vdots \\\\\n",
        "y_n\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "es el conjunto de observaciones de la variable objetivo.\n",
        "\n",
        "\n",
        "Crea una clase `RegresionLineal` con dos métodos, \n",
        "- `entrena`: toma como parámetros `X` e `y`, observaciones de las variables regresoras y objetivo, respectivamente, y calcula los coeficientes de la regresión lineal y los guarda en un atributo `_theta`. \n",
        "- `transforma`: toma como parámetro una serie de observaciones nuevas `X` y devuelve una estimación `y_hat` de la varible objetivo utilizando el método descrito anteriormente. \n",
        "\n",
        "Funciones que puede ser de ayuda: `np.linalg.inv`, `np.linalg.pinv`, `np.vstack`, `np.hstack`.\n",
        "\n",
        ":::"
      ],
      "metadata": {
        "id": "OnZBQDQ-tK3O"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}